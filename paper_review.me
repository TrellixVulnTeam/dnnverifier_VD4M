1. ESTIMATING H.264/AVC VIDEO PSNR WITHOUT REFERENCE(2008)

  used CIF(old camera type)
  worked with the encoded bit stream
  Baseline profile & PSNR & classic neural network 
  need to analyse H.264/AVC codec source code
  
2. Low-Complexity No-Reference PSNR Estimation for H.264/AVC Encoded Video(2013)
  
  the average bitrate of the video stream
  the mean QP of the I-frames of this video
  
  PSNR = b 1 +b 2 路log(rate)+b 3 路QP I +b 4 路rate路QP I
   
  Used Bitstream information.  
  Point: The ITU has standardized NR methods that rely on the bitstream as well as on the packet headers of video streams to assess the quality.

3. Predicting Full-Reference Video Quality Measures(2015)

 High Efficiency Video Coding (HEVC)  
 Used two-layer ANN
 
4. Evaluation of No Reference Bitstream-based Video Quality Assessment Methods(2017)

 There is Nothing important but Bitstream!!
 
 
Need to anlayse x264 raw-bitstream every renditions stream, and use as input stream of simple ANN
x264/AVC, Nvidia Encoder, Ts file contains bitstream? check. Need to encode option?


reference bitstream GH URL

https://github.com/leixiaohua1020

https://github.com/rainliu/aom_analyzer

https://github.com/Mainvooid/split_video_raw_bitstream

https://github.com/LongmanLee/lmApp

bitstream

https://manpages.ubuntu.com/manpages/artful/en/man1/ffmpeg-bitstream-filters.1.html

https://medium.com/@eyevinntechnology/generate-mpeg-ts-from-file-with-ffmpeg-7561181e6369

https://en.wikipedia.org/wiki/MPEG_transport_stream
https://netflixtechblog.com/introducing-svt-av1-a-scalable-open-source-av1-framework-c726cce3103a
https://www.cosmosoftware.io/blog/webrtc-video-quality-assessment

NeedTool & utility

VideoEye, Mpeg TS package analysis(MPEG-2_TS_Packet_Analyzer)

Workflow summary

- TS file generation, consist of H264 bitstream(with H264, Cuda codec encode)
  
  ffmpeg -i infile.mp4 -codec copy -bsf:v h264_mp4toannexb out.ts
  
  ffmpeg -i infile.mp4 -an -vcodec libx264 -crf 23 out.h264
  
- H264 Bitstream parsing and reconstruction
  
  Native Parsing and reconstruction(only use h264 library)  
  Recovery frame with FFmpeg
  
  Which is more effective for us? (speed , claculation cost ...)
  Need to some test and coding.  
 
- Train Dataset  
  
  https://github.com/Netflix/vmaf/blob/master/resource/doc/datasets.md
  Netflix Public Dataset, VQEG HD3 Dataset
  
  http://live.ece.utexas.edu/research/Quality/
  
  http://vision.eng.shizuoka.ac.jp/mod/page/view.php?id=24
  
  https://github.com/Tencent/DVQA/tree/master/dataset
  CVD2014, KoNViD-1k, LIVE-Qualcomm ,CSIQ, LIVE, NFLX, VIDEOSET,
  
  https://multimediacommons.wordpress.com/yfcc100m-core-dataset/ 
  YFCC100M dataset
  
  https://github.com/Archer-Tatsu/VQA-ODV (OK)
  VQA-ODV
  
  http://ivp.ee.cuhk.edu.hk/research/database/subjective/index.shtml (OK)
  IVP Subjective Quality Video Database	
  
  Other
  CASIA1,CASIA2,LIVE QVA, CSIQ ,Color Image Database TID2013
  
- Bitstream analyze 
  Basic profile 
  Macroblock
  Quantization parameter
  Motion vector
  
- Train model selection
  
  For satisfying speed going to use Three-layer (ANN)Artificial Neural Network.

- Traning over Dataset with sample attack
- Accuracy Estimatation
- Analyze bitstream attack vulnerability 

- image 

https://github.com/Adnan1011/NR-IQA-CNN
https://github.com/dmaniry/deepIQA
https://github.com/rmislam/PythonSIFT



